{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# 0) Install & Login & Drive Mount"
      ],
      "metadata": {
        "id": "x5N1ew4lywBH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q wandb polars xgboost imblearn"
      ],
      "metadata": {
        "id": "iLEfTbSvhORz"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "Ht66aWG_K8iH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "10f12ff1-7411-460f-b94f-7729f8b88934"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/notebook/notebookapp.py:191: SyntaxWarning: invalid escape sequence '\\/'\n",
            "  | |_| | '_ \\/ _` / _` |  _/ -_)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: (1) Create a W&B account\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: (2) Use an existing W&B account\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: (3) Don't visualize my results\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Enter your choice:"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: You chose 'Use an existing W&B account'\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into https://api.wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Create a new API key at: https://wandb.ai/authorize?ref=models\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Store your API key securely and do not share it.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Paste your API key and hit enter:"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " ··········\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: No netrc file found, creating one.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33m0326byeol\u001b[0m (\u001b[33m0326byeol-korea-ac-kr\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "import wandb\n",
        "wandb.login()\n",
        "# 계정 만들었으면, 2 누르고 본인 api 키 입력"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "wQfVSLopWPE0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "20f577a2-73f2-4c73-b865-33fdd6ea34e6"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1) Imports"
      ],
      "metadata": {
        "id": "3BGGsSp6y9Tn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import polars as pl\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import RobustScaler, OrdinalEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "from sklearn.metrics import (\n",
        "    roc_auc_score, roc_curve,\n",
        "    average_precision_score, precision_recall_curve,  # AUPRC/PR curve 핵심\n",
        "    confusion_matrix, classification_report,\n",
        "    accuracy_score, precision_score, recall_score, f1_score\n",
        ")\n",
        "\n",
        "from xgboost import XGBClassifier\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from collections import Counter\n",
        "import random\n",
        "\n",
        "import joblib\n",
        "import pickle\n",
        "import os"
      ],
      "metadata": {
        "id": "fDz_8IDBPyYC"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2) 테이블 병합(Polars + Parquet)\n",
        "\n"
      ],
      "metadata": {
        "id": "iqAaC6a5iidS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 파일 경로 설정 (본인의 경로에 맞게 수정하세요)\n",
        "base_path = \"/content/drive/MyDrive/data\"\n",
        "parquet_dir = os.path.join(base_path, \"parquet\")\n",
        "os.makedirs(parquet_dir, exist_ok=True)\n",
        "\n",
        "trans_csv = os.path.join(base_path, \"HI-Medium_Trans.csv\")\n",
        "acc_csv   = os.path.join(base_path, \"HI-Medium_accounts.csv\")"
      ],
      "metadata": {
        "id": "FkZ9-ct1gggi"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Parquet 저장 폴더\n",
        "trans_parquet = os.path.join(parquet_dir, \"HI-Medium_Trans.parquet\")\n",
        "acc_parquet   = os.path.join(parquet_dir, \"HI-Medium_accounts.parquet\")\n",
        "master_parquet = os.path.join(parquet_dir, \"HI-Medium_Master.parquet\")"
      ],
      "metadata": {
        "id": "ECnhVFEri1RL"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# (처음 1회만) CSV -> Parquet 변환(스트리밍으로 처리되어 메모리 안전)\n",
        "#    - 이미 parquet가 있으면 스킵\n",
        "if not os.path.exists(trans_parquet):\n",
        "    pl.scan_csv(\n",
        "        trans_csv,\n",
        "        infer_schema_length=10000,\n",
        "        try_parse_dates=False\n",
        "    ).sink_parquet(trans_parquet)\n",
        "\n",
        "if not os.path.exists(acc_parquet):\n",
        "    pl.scan_csv(\n",
        "        acc_csv,\n",
        "        infer_schema_length=10000,\n",
        "    ).sink_parquet(acc_parquet)"
      ],
      "metadata": {
        "id": "7gCTb07Dgo96"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Lazy 모드로 CSV 연결\n",
        "q_trans = pl.scan_parquet(trans_parquet)\n",
        "q_acc   = pl.scan_parquet(acc_parquet)"
      ],
      "metadata": {
        "id": "1q3y-gihgm4s"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#   Rates LazyFrame\n",
        "#   - Currency_Rate.csv를 따로 scan_csv해도 되는데,\n",
        "#     지금은 고정 테이블로 만든다고 했으니 lazy DF로 구성\n",
        "# -----------------------------\n",
        "rates_df = pl.DataFrame({\n",
        "    \"currency\": [\n",
        "        \"US Dollar\",\"Euro\",\"UK Pound\",\"Swiss Franc\",\"Canadian Dollar\",\n",
        "        \"Australian Dollar\",\"Bitcoin\",\"Saudi Riyal\",\"Shekel\",\"Brazil Real\",\n",
        "        \"Yuan\",\"Mexican Peso\",\"Ruble\",\"Rupee\",\"Yen\"\n",
        "    ],\n",
        "    \"rate\": [\n",
        "        1.0,0.99,1.15,1.03,0.76,\n",
        "        0.67,20000.0,0.266,0.29,0.19,\n",
        "        0.14,0.05,0.017,0.0125,0.007\n",
        "    ]\n",
        "}).lazy()\n"
      ],
      "metadata": {
        "id": "SF3zxeUVCkP-"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# -----------------------------\n",
        "#  컬럼명 normalize (데이터마다 Account/Account.1 케이스가 있어서 방어)\n",
        "# -----------------------------\n",
        "# trans의 실제 컬럼을 먼저 확인하고 싶으면:\n",
        "# print(q_trans.columns)  # Lazy에서도 가능\n",
        "\n",
        "q_trans = (\n",
        "    q_trans\n",
        "    # 만약 컬럼명이 'Account', 'Account_duplicated_0'이라고 가정하면:\n",
        "    .rename({\n",
        "        \"Account\": \"From Account\",      # 첫 번째 Account는 보내는 사람\n",
        "        \"Account_duplicated_0\": \"To Account\"       # 두 번째(중복) Account는 받는 사람\n",
        "        # ※ 주의: 위에서 print(q_trans.columns)로 확인한 실제 이름과 다르면\n",
        "        #         여기를 실제 이름에 맞춰 수정해야 합니다!\n",
        "    })\n",
        ")\n",
        "\n",
        "# 이제 trans는 최소한 From Account / To Account 컬럼이 있다고 가정하고 진행"
      ],
      "metadata": {
        "id": "HymHzA_TCwAZ"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# -----------------------------\n",
        "#  Master build\n",
        "#   1) Receiving Currency로 Amount Received USD\n",
        "#   2) Payment Currency로 Amount Paid USD\n",
        "#   3) accounts를 sender/receiver로 2번 left join (suffix 처리)\n",
        "# -----------------------------\n",
        "q_master = (\n",
        "    q_trans\n",
        "\n",
        "    # --- (1) Amount Received USD (Receiving Currency 기준)\n",
        "    .join(\n",
        "        rates_df.rename({\"currency\": \"Receiving Currency\", \"rate\": \"recv_rate\"}),\n",
        "        on=\"Receiving Currency\",\n",
        "        how=\"left\"\n",
        "    )\n",
        "    .with_columns([\n",
        "        (pl.col(\"recv_rate\").fill_null(1.0)).alias(\"recv_rate\"),\n",
        "        (pl.col(\"Amount Received\") * pl.col(\"recv_rate\")).alias(\"Amount_Received_USD\")\n",
        "    ])\n",
        "\n",
        "    # --- (2) Amount Paid USD (Payment Currency 기준)\n",
        "    .join(\n",
        "        rates_df.rename({\"currency\": \"Payment Currency\", \"rate\": \"pay_rate\"}),\n",
        "        on=\"Payment Currency\",\n",
        "        how=\"left\"\n",
        "    )\n",
        "    .with_columns([\n",
        "        (pl.col(\"pay_rate\").fill_null(1.0)).alias(\"pay_rate\"),\n",
        "        (pl.col(\"Amount Paid\") * pl.col(\"pay_rate\")).alias(\"Amount_Paid_USD\")\n",
        "    ])\n",
        "\n",
        "    # --- (3) Sender account join\n",
        "    .join(\n",
        "        q_acc.select([\"Account Number\", \"Entity Name\", \"Bank Name\"]),\n",
        "        left_on=\"From Account\",\n",
        "        right_on=\"Account Number\",\n",
        "        how=\"left\",\n",
        "        suffix=\"_sender\"\n",
        "    )\n",
        "    .rename({\n",
        "        \"Entity Name\": \"Sender_Entity\",\n",
        "        \"Bank Name\": \"Sender_Bank_Name\"\n",
        "    })\n",
        "\n",
        "    # --- (4) Receiver account join (컬럼 충돌 방지 위해 suffix 사용)\n",
        "    .join(\n",
        "        q_acc.select([\"Account Number\", \"Entity Name\", \"Bank Name\"]),\n",
        "        left_on=\"To Account\",\n",
        "        right_on=\"Account Number\",\n",
        "        how=\"left\",\n",
        "        suffix=\"_receiver\"\n",
        "    )\n",
        "    .rename({\n",
        "        \"Entity Name\": \"Receiver_Entity\",\n",
        "        \"Bank Name\": \"Receiver_Bank_Name\"\n",
        "    })\n",
        "\n",
        "    # (선택) rate 컬럼 정리하고 싶으면:\n",
        "   .drop([\"recv_rate\",\"pay_rate\"])\n",
        ")"
      ],
      "metadata": {
        "id": "_MPWkroNC_WP"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# -----------------------------\n",
        "#  sink to Parquet (Streaming write)\n",
        "# -----------------------------\n",
        "print(\"Writing master table to Parquet (streaming)...\")\n",
        "q_master.sink_parquet(master_parquet)\n",
        "print(f\"Done. Saved: {master_parquet}\")\n",
        "\n",
        "# 이후에는 이렇게 빠르게 로드\n",
        "# q_master = pl.scan_parquet(master_parquet)"
      ],
      "metadata": {
        "id": "VkQhu5IDDdmI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d6fe9a9e-2302-4316-ea1c-608cdbf31c47"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing master table to Parquet (streaming)...\n",
            "Done. Saved: /content/drive/MyDrive/data/parquet/HI-Medium_Master.parquet\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "master_parquet = \"/content/drive/MyDrive/data/parquet/HI-Medium_Master.parquet\"\n",
        "\n",
        "q_master = pl.scan_parquet(master_parquet)"
      ],
      "metadata": {
        "id": "tRBvTf20Ey5u"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4) Timestamp"
      ],
      "metadata": {
        "id": "PWm1iUdqpVP1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================================================\n",
        "# Timestamp 파싱 + 정렬 준비\n",
        "#   - 원본 Timestamp(string) 유지\n",
        "#   - ts(Datetime) 새로 생성\n",
        "#   - ts 파싱 실패(null) 개수 출력\n",
        "# =========================================================\n",
        "total_rows = q_master.select(pl.len()).collect().item()\n",
        "\n",
        "q_master = q_master.with_columns(\n",
        "    pl.col(\"Timestamp\")\n",
        "      .str.strptime(pl.Datetime, format=\"%Y/%m/%d %H:%M\", strict=False)\n",
        "      .alias(\"ts\")\n",
        ")\n",
        "\n",
        "null_ts_rows = (\n",
        "    q_master.filter(pl.col(\"ts\").is_null())\n",
        "     .select(pl.len())\n",
        "     .collect()\n",
        "     .item()\n",
        ")\n",
        "\n",
        "valid_rows = total_rows - null_ts_rows\n",
        "\n",
        "print(f\"Total rows                    : {total_rows:,}\")\n",
        "print(f\"Rows with NULL ts (parse fail): {null_ts_rows:,}\")\n",
        "print(f\"Valid ts rows                 : {valid_rows:,}\")\n",
        "\n",
        "# split은 ts가 유효한 행만 대상으로 진행 (추천)\n",
        "q_valid = q_master.filter(pl.col(\"ts\").is_not_null())"
      ],
      "metadata": {
        "id": "9CnYSpvhtlLa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "190dc9cc-5a2c-49df-e5db-785e6ab8d40c"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total rows                    : 31,898,669\n",
            "Rows with NULL ts (parse fail): 0\n",
            "Valid ts rows                 : 31,898,669\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================================================\n",
        "# time-based split 기준(ts cut) 계산 (60:20:20)\n",
        "#   - collect 최소화: 경계 ts 2개만 뽑음\n",
        "# =========================================================\n",
        "n = q_valid.select(pl.len()).collect().item()\n",
        "train_end_idx = int(n * 0.6)\n",
        "val_end_idx   = int(n * 0.8)\n",
        "\n",
        "q_sorted = q_valid.sort(\"ts\")\n",
        "\n",
        "train_cut_ts = (\n",
        "    q_sorted.select(\"ts\")\n",
        "            .slice(train_end_idx, 1)\n",
        "            .collect()\n",
        "            .item()\n",
        ")\n",
        "\n",
        "val_cut_ts = (\n",
        "    q_sorted.select(\"ts\")\n",
        "            .slice(val_end_idx, 1)\n",
        "            .collect()\n",
        "            .item()\n",
        ")\n",
        "\n",
        "print(\"Train cutoff ts:\", train_cut_ts)\n",
        "print(\"Val cutoff ts  :\", val_cut_ts)"
      ],
      "metadata": {
        "id": "4aXFnKi4t_Bz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "65a0639b-be0a-4290-d030-f6099d0ddb31"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train cutoff ts: 2022-09-09 20:43:00\n",
            "Val cutoff ts  : 2022-09-14 05:46:00\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================================================\n",
        "# split 컬럼 부여 (train/val/test)\n",
        "# =========================================================\n",
        "q_split = q_sorted.with_columns(\n",
        "    pl.when(pl.col(\"ts\") <= train_cut_ts)\n",
        "      .then(pl.lit(\"train\"))\n",
        "      .when(pl.col(\"ts\") <= val_cut_ts)\n",
        "      .then(pl.lit(\"val\"))\n",
        "      .otherwise(pl.lit(\"test\"))\n",
        "      .alias(\"split\")\n",
        ")\n",
        "\n",
        "# sanity check: split 분포\n",
        "split_counts = (\n",
        "    q_split.group_by(\"split\")\n",
        "           .agg(pl.len().alias(\"rows\"))\n",
        "           .collect()\n",
        ")\n",
        "print(split_counts)\n",
        "\n",
        "# 라벨 비율 sanity check (optional)\n",
        "label_counts = (\n",
        "    q_split.group_by([\"split\", \"Is Laundering\"])\n",
        "           .agg(pl.len().alias(\"rows\"))\n",
        "           .collect()\n",
        ")\n",
        "print(label_counts)"
      ],
      "metadata": {
        "id": "vr38CNyFuD0T",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ab1e8f3c-e686-4234-ac22-789da855ad0a"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "shape: (3, 2)\n",
            "┌───────┬──────────┐\n",
            "│ split ┆ rows     │\n",
            "│ ---   ┆ ---      │\n",
            "│ str   ┆ u32      │\n",
            "╞═══════╪══════════╡\n",
            "│ test  ┆ 6378958  │\n",
            "│ train ┆ 19139731 │\n",
            "│ val   ┆ 6379980  │\n",
            "└───────┴──────────┘\n",
            "shape: (6, 3)\n",
            "┌───────┬───────────────┬──────────┐\n",
            "│ split ┆ Is Laundering ┆ rows     │\n",
            "│ ---   ┆ ---           ┆ ---      │\n",
            "│ str   ┆ i64           ┆ u32      │\n",
            "╞═══════╪═══════════════╪══════════╡\n",
            "│ train ┆ 0             ┆ 19124195 │\n",
            "│ val   ┆ 1             ┆ 9054     │\n",
            "│ test  ┆ 0             ┆ 6368318  │\n",
            "│ val   ┆ 0             ┆ 6370926  │\n",
            "│ train ┆ 1             ┆ 15536    │\n",
            "│ test  ┆ 1             ┆ 10640    │\n",
            "└───────┴───────────────┴──────────┘\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 6) bucket_ts 생성 (1h)"
      ],
      "metadata": {
        "id": "p3Hl4zeqpf9D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================================================\n",
        "# bucket_ts 생성 (ts → 1h truncate)\n",
        "#   - baseline v1: 거래(row) 단위 모델링이지만,\n",
        "#     이후 확장을 위해 bucket_ts는 만들어 둠\n",
        "# =========================================================\n",
        "q_feat = q_split.with_columns(\n",
        "    pl.col(\"ts\").dt.truncate(\"1h\").alias(\"bucket_ts\")\n",
        ").with_columns(\n",
        "    pl.col(\"bucket_ts\").dt.strftime(\"%Y-%m-%d %H:%M:%S\").alias(\"bucket_ts_str\")\n",
        ")\n",
        "\n",
        "# bucket 분포 sanity check (optional)\n",
        "bucket_check = (\n",
        "    q_feat.filter(pl.col(\"split\") == \"train\")\n",
        "          .select([\n",
        "              pl.col(\"bucket_ts\").min().alias(\"train_bucket_min\"),\n",
        "              pl.col(\"bucket_ts\").max().alias(\"train_bucket_max\"),\n",
        "              pl.len().alias(\"train_rows\"),\n",
        "          ])\n",
        "          .collect()\n",
        ")\n",
        "print(bucket_check)"
      ],
      "metadata": {
        "id": "wmdJp0u2uTFz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f3caa12e-b8de-4734-e506-f34fc2bc0bc0"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "shape: (1, 3)\n",
            "┌─────────────────────┬─────────────────────┬────────────┐\n",
            "│ train_bucket_min    ┆ train_bucket_max    ┆ train_rows │\n",
            "│ ---                 ┆ ---                 ┆ ---        │\n",
            "│ datetime[μs]        ┆ datetime[μs]        ┆ u32        │\n",
            "╞═════════════════════╪═════════════════════╪════════════╡\n",
            "│ 2022-09-01 00:00:00 ┆ 2022-09-09 20:00:00 ┆ 19139731   │\n",
            "└─────────────────────┴─────────────────────┴────────────┘\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#“노드 키” 만들기 (송신/수신 각각)\n",
        "q_feat = q_feat.with_columns([\n",
        "    (pl.col(\"From Account\").cast(pl.Utf8) + \"_\" + pl.col(\"bucket_ts_str\").cast(pl.Utf8)).alias(\"sender_node\"),\n",
        "    (pl.col(\"To Account\").cast(pl.Utf8)   + \"_\" + pl.col(\"bucket_ts_str\").cast(pl.Utf8)).alias(\"receiver_node\"),\n",
        "])"
      ],
      "metadata": {
        "id": "hhnOuhoSbL5F"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 8) 피처 엔지니어링"
      ],
      "metadata": {
        "id": "DC51OTB2ps1i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# -------------------------\n",
        "# (A) 상수/룩업 리스트\n",
        "# -------------------------\n",
        "PAYMENT_FORMATS = [\"ACH\", \"Cheque\", \"Bitcoin\", \"Cash\", \"Credit Card\", \"Wire\", \"Reinvestment\"]\n",
        "\n",
        "HIGH_RISK_SENDER_BANKS = [\n",
        "    \"National Bank of Dallas\", \"Savings Bank of Augusta\", \"China Bank #27\",\n",
        "    \"India Bank #96\", \"Brazil Bank #128\", \"National Bank of Milford\",\n",
        "    \"Savings Bank of Sacramento\", \"Saudi Arabia Bank #14\", \"Israel Bank #16\",\n",
        "    \"Golden Credit Union\"\n",
        "]\n",
        "\n",
        "HIGH_RISK_RECEIVER_BANKS = [\n",
        "    \"China Bank #292\", \"China Bank #27\", \"China Bank #22\", \"Japan Bank #143\",\n",
        "    \"Brazil Bank #50\", \"Bank of Denver\", \"Saudi Arabia Bank #56\",\n",
        "    \"Israel Bank #48\", \"The Pine Bank\", \"National Bank of Milford\"\n",
        "]\n",
        "\n",
        "# 엔티티 타입 가중치 (v1: 단순 룰)\n",
        "ENTITY_TYPE_SCORE_MAP = {\n",
        "    \"Corporation\": 2.0,\n",
        "    \"Sole Proprietorship\": 1.5\n",
        "}\n",
        "\n",
        "# Payment method risk (v1: 단순 룰)\n",
        "# (정확한 가중치는 EDA에서 조정 가능. 지금은 “비중 높았던 수단에 가중”만 구현)\n",
        "PAYMENT_RISK_MAP = {\n",
        "    \"ACH\": 3.0,\n",
        "    \"Bitcoin\": 2.5,\n",
        "    \"Cheque\": 2.5,\n",
        "    \"Cash\": 1.5,\n",
        "    \"Credit Card\": 1.3,\n",
        "    \"Wire\": 1.0,\n",
        "    \"Reinvestment\": 1.0\n",
        "}"
      ],
      "metadata": {
        "id": "5pJPD2g96Tac"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# -------------------------\n",
        "# (B) Timestamp 파생\n",
        "# -------------------------\n",
        "q_feat = q_feat.with_columns([\n",
        "    pl.col(\"ts\").dt.hour().cast(pl.Int16).alias(\"hour\"),\n",
        "    pl.col(\"ts\").dt.weekday().cast(pl.Int8).alias(\"day_of_week\"),  # 월=1 ~ 일=7 (Polars 기본)\n",
        "    pl.col(\"ts\").dt.weekday().is_in([6, 7]).alias(\"is_weekend\"),\n",
        "    pl.col(\"ts\").dt.date().alias(\"ts_day\"),\n",
        "\n",
        "    # 새벽 여부 (예: 0~5시)\n",
        "    pl.col(\"ts\").dt.hour().is_between(0, 5).alias(\"is_dawn\"),\n",
        "\n",
        "    # TimeofDay bucket (예시: 새벽/오전/오후/밤)\n",
        "    pl.when(pl.col(\"ts\").dt.hour().is_between(0, 5)).then(pl.lit(\"dawn\"))\n",
        "      .when(pl.col(\"ts\").dt.hour().is_between(6, 11)).then(pl.lit(\"morning\"))\n",
        "      .when(pl.col(\"ts\").dt.hour().is_between(12, 17)).then(pl.lit(\"afternoon\"))\n",
        "      .otherwise(pl.lit(\"evening\"))\n",
        "      .alias(\"timeofday_bucket\"),\n",
        "])"
      ],
      "metadata": {
        "id": "uA3pnfEN8lQg"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# -------------------------\n",
        "# (C) Amount 파생 (float32 + log)\n",
        "# -------------------------\n",
        "q_feat = q_feat.with_columns([\n",
        "    # float32 캐스팅\n",
        "    pl.col(\"Amount_Paid_USD\").cast(pl.Float32),\n",
        "    pl.col(\"Amount_Received_USD\").cast(pl.Float32),\n",
        "\n",
        "    # log1p\n",
        "    pl.col(\"Amount_Paid_USD\").log1p().alias(\"log_amount_paid_usd\"),\n",
        "    pl.col(\"Amount_Received_USD\").log1p().alias(\"log_amount_received_usd\"),\n",
        "\n",
        "    # Round number (1000 단위)\n",
        "    (pl.col(\"Amount_Paid_USD\") % 1000 == 0).alias(\"is_round_1000_paid\"),\n",
        "    (pl.col(\"Amount_Received_USD\") % 1000 == 0).alias(\"is_round_1000_received\"),\n",
        "\n",
        "    # 더 강한 라운드 (10000 단위)\n",
        "    (pl.col(\"Amount_Paid_USD\") % 10000 == 0).alias(\"is_round_10000_paid\"),\n",
        "])"
      ],
      "metadata": {
        "id": "gQtouWde8omW"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# -------------------------\n",
        "# (D) Payment Format 원핫 + 파생\n",
        "# -------------------------\n",
        "# 원핫(각 format별 bool)\n",
        "q_feat = q_feat.with_columns([\n",
        "    (pl.col(\"Payment Format\") == \"ACH\").alias(\"is_ach\"),\n",
        "    (pl.col(\"Payment Format\") == \"Cheque\").alias(\"is_cheque\"),\n",
        "    (pl.col(\"Payment Format\") == \"Bitcoin\").alias(\"is_bitcoin_fmt\"),\n",
        "    (pl.col(\"Payment Format\") == \"Cash\").alias(\"is_cash\"),\n",
        "    (pl.col(\"Payment Format\") == \"Credit Card\").alias(\"is_credit_card\"),\n",
        "    (pl.col(\"Payment Format\") == \"Wire\").alias(\"is_wire\"),\n",
        "    (pl.col(\"Payment Format\") == \"Reinvestment\").alias(\"is_reinvestment\"),\n",
        "])\n",
        "\n",
        "# Crypto 여부 (format이 Bitcoin이거나 currency가 Bitcoin이면 True)\n",
        "q_feat = q_feat.with_columns([\n",
        "    ((pl.col(\"Payment Format\") == \"Bitcoin\") | (pl.col(\"Payment Currency\") == \"Bitcoin\"))\n",
        "      .alias(\"is_crypto_transfer\"),\n",
        "\n",
        "    # High value ACH (>= 1,000,000 USD & ACH)\n",
        "    ((pl.col(\"Payment Format\") == \"ACH\") & (pl.col(\"Amount_Paid_USD\") >= 1_000_000))\n",
        "      .alias(\"is_high_value_ach\"),\n",
        "])\n",
        "\n",
        "# Payment_Method_Risk (format 기반 가중치)\n",
        "q_feat = q_feat.with_columns([\n",
        "    pl.col(\"Payment Format\")\n",
        "      .replace(PAYMENT_RISK_MAP, default=1.0)\n",
        "      .cast(pl.Float32)\n",
        "      .alias(\"payment_method_risk\"),\n",
        "])\n",
        "\n",
        "# format × amount interaction (v1용)\n",
        "q_feat = q_feat.with_columns([\n",
        "    (pl.col(\"payment_method_risk\") * pl.col(\"log_amount_paid_usd\")).alias(\"risk_x_log_paid\"),\n",
        "    (pl.col(\"is_ach\").cast(pl.Int8) * pl.col(\"log_amount_paid_usd\")).alias(\"ach_x_log_paid\"),\n",
        "    (pl.col(\"is_bitcoin_fmt\").cast(pl.Int8) * pl.col(\"log_amount_paid_usd\")).alias(\"btc_x_log_paid\"),\n",
        "])"
      ],
      "metadata": {
        "id": "eur3u7lI9IY9"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# -------------------------\n",
        "# (E) Entity type 파싱 + 점수\n",
        "# -------------------------\n",
        "# \"Corporation #26522\" → \"Corporation\"\n",
        "q_feat = q_feat.with_columns([\n",
        "    pl.col(\"Sender_Entity\")\n",
        "      .cast(pl.Utf8)\n",
        "      .str.replace(r\"\\s*#\\d+.*$\", \"\")   # \"#숫자\" 이후 제거\n",
        "      .alias(\"sender_entity_type\"),\n",
        "\n",
        "    pl.col(\"Receiver_Entity\")\n",
        "      .cast(pl.Utf8)\n",
        "      .str.replace(r\"\\s*#\\d+.*$\", \"\")\n",
        "      .alias(\"receiver_entity_type\"),\n",
        "])\n",
        "\n",
        "# 타입 점수\n",
        "q_feat = q_feat.with_columns([\n",
        "    pl.col(\"sender_entity_type\")\n",
        "      .replace(ENTITY_TYPE_SCORE_MAP, default=1.0)\n",
        "      .cast(pl.Float32)\n",
        "      .alias(\"sender_entity_type_score\"),\n",
        "\n",
        "    pl.col(\"receiver_entity_type\")\n",
        "      .replace(ENTITY_TYPE_SCORE_MAP, default=1.0)\n",
        "      .cast(pl.Float32)\n",
        "      .alias(\"receiver_entity_type_score\"),\n",
        "])\n"
      ],
      "metadata": {
        "id": "WQRpsKAr9ggw"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# -------------------------\n",
        "# (F) High risk bank flags\n",
        "# -------------------------\n",
        "q_feat = q_feat.with_columns([\n",
        "    pl.col(\"Sender_Bank_Name\").is_in(HIGH_RISK_SENDER_BANKS).alias(\"high_risk_sender_bank_flag\"),\n",
        "    pl.col(\"Receiver_Bank_Name\").is_in(HIGH_RISK_RECEIVER_BANKS).alias(\"high_risk_receiver_bank_flag\"),\n",
        "])"
      ],
      "metadata": {
        "id": "MpX4yPEW9qUW"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 확인하고 싶은 핵심 피처만 뽑아서 head 5\n",
        "inspect_cols = [\n",
        "    # timestamp 관련\n",
        "    \"Timestamp\", \"ts\", \"hour\", \"day_of_week\", \"is_weekend\", \"is_dawn\", \"timeofday_bucket\",\n",
        "\n",
        "    # amount 관련\n",
        "    \"Amount_Paid_USD\", \"log_amount_paid_usd\",\n",
        "    \"Amount_Received_USD\", \"log_amount_received_usd\",\n",
        "    \"is_round_1000_paid\",\n",
        "\n",
        "    # payment format\n",
        "    \"Payment Format\",\n",
        "    \"is_ach\", \"is_bitcoin_fmt\", \"is_crypto_transfer\",\n",
        "    \"is_high_value_ach\", \"payment_method_risk\", \"risk_x_log_paid\",\n",
        "\n",
        "    # entity / bank\n",
        "    \"Sender_Entity\", \"sender_entity_type\", \"sender_entity_type_score\",\n",
        "    \"Sender_Bank_Name\", \"high_risk_sender_bank_flag\",\n",
        "\n",
        "    # label / split\n",
        "    \"Is Laundering\", \"split\"\n",
        "]\n",
        "\n",
        "q_feat.select(inspect_cols).head(5).collect()"
      ],
      "metadata": {
        "id": "j1CRFmmw_RUM",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 431
        },
        "outputId": "f46ea6c6-afe1-47a7-8bde-52a918e8d1a7"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "shape: (5, 26)\n",
              "┌─────────────┬─────────────┬──────┬────────────┬───┬────────────┬────────────┬────────────┬───────┐\n",
              "│ Timestamp   ┆ ts          ┆ hour ┆ day_of_wee ┆ … ┆ Sender_Ban ┆ high_risk_ ┆ Is         ┆ split │\n",
              "│ ---         ┆ ---         ┆ ---  ┆ k          ┆   ┆ k_Name     ┆ sender_ban ┆ Laundering ┆ ---   │\n",
              "│ str         ┆ datetime[μs ┆ i16  ┆ ---        ┆   ┆ ---        ┆ k_flag     ┆ ---        ┆ str   │\n",
              "│             ┆ ]           ┆      ┆ i8         ┆   ┆ str        ┆ ---        ┆ i64        ┆       │\n",
              "│             ┆             ┆      ┆            ┆   ┆            ┆ bool       ┆            ┆       │\n",
              "╞═════════════╪═════════════╪══════╪════════════╪═══╪════════════╪════════════╪════════════╪═══════╡\n",
              "│ 2022/09/01  ┆ 2022-09-01  ┆ 0    ┆ 4          ┆ … ┆ France     ┆ false      ┆ 0          ┆ train │\n",
              "│ 00:00       ┆ 00:00:00    ┆      ┆            ┆   ┆ Bank #1654 ┆            ┆            ┆       │\n",
              "│ 2022/09/01  ┆ 2022-09-01  ┆ 0    ┆ 4          ┆ … ┆ Hilltop    ┆ false      ┆ 0          ┆ train │\n",
              "│ 00:00       ┆ 00:00:00    ┆      ┆            ┆   ┆ Cooperativ ┆            ┆            ┆       │\n",
              "│             ┆             ┆      ┆            ┆   ┆ e Bank     ┆            ┆            ┆       │\n",
              "│ 2022/09/01  ┆ 2022-09-01  ┆ 0    ┆ 4          ┆ … ┆ Flagstone  ┆ false      ┆ 0          ┆ train │\n",
              "│ 00:00       ┆ 00:00:00    ┆      ┆            ┆   ┆ Thrift     ┆            ┆            ┆       │\n",
              "│ 2022/09/01  ┆ 2022-09-01  ┆ 0    ┆ 4          ┆ … ┆ Savings    ┆ false      ┆ 0          ┆ train │\n",
              "│ 00:00       ┆ 00:00:00    ┆      ┆            ┆   ┆ Bank of    ┆            ┆            ┆       │\n",
              "│             ┆             ┆      ┆            ┆   ┆ Columbus   ┆            ┆            ┆       │\n",
              "│ 2022/09/01  ┆ 2022-09-01  ┆ 0    ┆ 4          ┆ … ┆ Bank of    ┆ false      ┆ 0          ┆ train │\n",
              "│ 00:00       ┆ 00:00:00    ┆      ┆            ┆   ┆ Philadelph ┆            ┆            ┆       │\n",
              "│             ┆             ┆      ┆            ┆   ┆ ia         ┆            ┆            ┆       │\n",
              "└─────────────┴─────────────┴──────┴────────────┴───┴────────────┴────────────┴────────────┴───────┘"
            ],
            "text/html": [
              "<div><style>\n",
              ".dataframe > thead > tr,\n",
              ".dataframe > tbody > tr {\n",
              "  text-align: right;\n",
              "  white-space: pre-wrap;\n",
              "}\n",
              "</style>\n",
              "<small>shape: (5, 26)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>Timestamp</th><th>ts</th><th>hour</th><th>day_of_week</th><th>is_weekend</th><th>is_dawn</th><th>timeofday_bucket</th><th>Amount_Paid_USD</th><th>log_amount_paid_usd</th><th>Amount_Received_USD</th><th>log_amount_received_usd</th><th>is_round_1000_paid</th><th>Payment Format</th><th>is_ach</th><th>is_bitcoin_fmt</th><th>is_crypto_transfer</th><th>is_high_value_ach</th><th>payment_method_risk</th><th>risk_x_log_paid</th><th>Sender_Entity</th><th>sender_entity_type</th><th>sender_entity_type_score</th><th>Sender_Bank_Name</th><th>high_risk_sender_bank_flag</th><th>Is Laundering</th><th>split</th></tr><tr><td>str</td><td>datetime[μs]</td><td>i16</td><td>i8</td><td>bool</td><td>bool</td><td>str</td><td>f32</td><td>f64</td><td>f32</td><td>f64</td><td>bool</td><td>str</td><td>bool</td><td>bool</td><td>bool</td><td>bool</td><td>f32</td><td>f64</td><td>str</td><td>str</td><td>f32</td><td>str</td><td>bool</td><td>i64</td><td>str</td></tr></thead><tbody><tr><td>&quot;2022/09/01 00:00&quot;</td><td>2022-09-01 00:00:00</td><td>0</td><td>4</td><td>false</td><td>true</td><td>&quot;dawn&quot;</td><td>589.366821</td><td>6.380744</td><td>589.366821</td><td>6.380744</td><td>false</td><td>&quot;Reinvestment&quot;</td><td>false</td><td>false</td><td>false</td><td>false</td><td>1.0</td><td>6.380744</td><td>&quot;Partnership #81036&quot;</td><td>&quot;Partnership&quot;</td><td>1.0</td><td>&quot;France Bank #1654&quot;</td><td>false</td><td>0</td><td>&quot;train&quot;</td></tr><tr><td>&quot;2022/09/01 00:00&quot;</td><td>2022-09-01 00:00:00</td><td>0</td><td>4</td><td>false</td><td>true</td><td>&quot;dawn&quot;</td><td>11.48</td><td>2.524127</td><td>11.48</td><td>2.524127</td><td>false</td><td>&quot;Reinvestment&quot;</td><td>false</td><td>false</td><td>false</td><td>false</td><td>1.0</td><td>2.524127</td><td>&quot;Sole Proprietorship #51143&quot;</td><td>&quot;Sole Proprietorship&quot;</td><td>1.5</td><td>&quot;Hilltop Cooperative Bank&quot;</td><td>false</td><td>0</td><td>&quot;train&quot;</td></tr><tr><td>&quot;2022/09/01 00:00&quot;</td><td>2022-09-01 00:00:00</td><td>0</td><td>4</td><td>false</td><td>true</td><td>&quot;dawn&quot;</td><td>1838.040039</td><td>7.516999</td><td>1838.040039</td><td>7.516999</td><td>false</td><td>&quot;Reinvestment&quot;</td><td>false</td><td>false</td><td>false</td><td>false</td><td>1.0</td><td>7.516999</td><td>&quot;Sole Proprietorship #30920&quot;</td><td>&quot;Sole Proprietorship&quot;</td><td>1.5</td><td>&quot;Flagstone Thrift&quot;</td><td>false</td><td>0</td><td>&quot;train&quot;</td></tr><tr><td>&quot;2022/09/01 00:00&quot;</td><td>2022-09-01 00:00:00</td><td>0</td><td>4</td><td>false</td><td>true</td><td>&quot;dawn&quot;</td><td>3290.0</td><td>8.098947</td><td>3290.0</td><td>8.098947</td><td>false</td><td>&quot;ACH&quot;</td><td>true</td><td>false</td><td>false</td><td>false</td><td>3.0</td><td>24.29684</td><td>&quot;Sole Proprietorship #18906&quot;</td><td>&quot;Sole Proprietorship&quot;</td><td>1.5</td><td>&quot;Savings Bank of Columbus&quot;</td><td>false</td><td>0</td><td>&quot;train&quot;</td></tr><tr><td>&quot;2022/09/01 00:00&quot;</td><td>2022-09-01 00:00:00</td><td>0</td><td>4</td><td>false</td><td>true</td><td>&quot;dawn&quot;</td><td>1494.589966</td><td>7.310276</td><td>1494.589966</td><td>7.310276</td><td>false</td><td>&quot;Reinvestment&quot;</td><td>false</td><td>false</td><td>false</td><td>false</td><td>1.0</td><td>7.310276</td><td>&quot;Corporation #8424&quot;</td><td>&quot;Corporation&quot;</td><td>2.0</td><td>&quot;Bank of Philadelphia&quot;</td><td>false</td><td>0</td><td>&quot;train&quot;</td></tr></tbody></table></div>"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 9) 모델에 안 넣을 컬럼 drop    "
      ],
      "metadata": {
        "id": "CEUftEd9pzES"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "DROP_COLS_V1 = [\n",
        "    # raw time / ids\n",
        "    \"Timestamp\", \"ts\", \"bucket_ts\", \"bucket_ts_str\",\n",
        "\n",
        "    # account / bank / entity identifiers\n",
        "    # \"From Account\", \"To Account\",               -> baseline-ml-v2에서는 주석 해제(계좌번호 드랍)\n",
        "    # \"From Bank\", \"To Bank\",\n",
        "    # \"Sender_Bank_Name\", \"Receiver_Bank_Name\",\n",
        "    # \"Sender_Entity\", \"Receiver_Entity\",\n",
        "\n",
        "    # intermediate entity cols\n",
        "    \"sender_entity_type\", \"receiver_entity_type\",\n",
        "\n",
        "    # raw amount columns\n",
        "    \"Amount Paid\", \"Amount Received\",\n",
        "    # \"Amount_Paid_USD\", \"Amount_Received_USD\",\n",
        "\n",
        "    # currency\n",
        "    # \"Receiving Currency\", \"Payment Currency\"\n",
        "\n",
        "    \"sender_node\", \"receiver_node\",\n",
        "]\n",
        "\n",
        "q_model = q_feat.drop([c for c in DROP_COLS_V1 if c in q_feat.columns])"
      ],
      "metadata": {
        "id": "88FgOmXoAhpg"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# drop 전 51\n",
        "print(len(q_model.columns))\n",
        "print(q_model.columns)"
      ],
      "metadata": {
        "id": "5E8bJ97eMD1f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "06d4fac6-469c-44b0-aaf9-1d076ccd0399"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "43\n",
            "['From Bank', 'From Account', 'To Bank', 'To Account', 'Receiving Currency', 'Payment Currency', 'Payment Format', 'Is Laundering', 'Amount_Received_USD', 'Amount_Paid_USD', 'Sender_Entity', 'Sender_Bank_Name', 'Receiver_Entity', 'Receiver_Bank_Name', 'split', 'hour', 'day_of_week', 'is_weekend', 'ts_day', 'is_dawn', 'timeofday_bucket', 'log_amount_paid_usd', 'log_amount_received_usd', 'is_round_1000_paid', 'is_round_1000_received', 'is_round_10000_paid', 'is_ach', 'is_cheque', 'is_bitcoin_fmt', 'is_cash', 'is_credit_card', 'is_wire', 'is_reinvestment', 'is_crypto_transfer', 'is_high_value_ach', 'payment_method_risk', 'risk_x_log_paid', 'ach_x_log_paid', 'btc_x_log_paid', 'sender_entity_type_score', 'receiver_entity_type_score', 'high_risk_sender_bank_flag', 'high_risk_receiver_bank_flag']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "FLOAT64_COLS = [\n",
        "    \"log_amount_paid_usd\",\n",
        "    \"log_amount_received_usd\",\n",
        "    \"risk_x_log_paid\",\n",
        "    \"ach_x_log_paid\",\n",
        "    \"btc_x_log_paid\",\n",
        "]\n",
        "\n",
        "q_model = q_model.with_columns([\n",
        "    pl.col(c).cast(pl.Float32) for c in FLOAT64_COLS\n",
        "])"
      ],
      "metadata": {
        "id": "28-My1npNriq"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "q_model.schema"
      ],
      "metadata": {
        "id": "yJvmrI_UNvC3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b526b8ff-0387-4182-c50b-1fdd54305fa0"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Schema([('From Bank', Int64),\n",
              "        ('From Account', String),\n",
              "        ('To Bank', Int64),\n",
              "        ('To Account', String),\n",
              "        ('Receiving Currency', String),\n",
              "        ('Payment Currency', String),\n",
              "        ('Payment Format', String),\n",
              "        ('Is Laundering', Int64),\n",
              "        ('Amount_Received_USD', Float32),\n",
              "        ('Amount_Paid_USD', Float32),\n",
              "        ('Sender_Entity', String),\n",
              "        ('Sender_Bank_Name', String),\n",
              "        ('Receiver_Entity', String),\n",
              "        ('Receiver_Bank_Name', String),\n",
              "        ('split', String),\n",
              "        ('hour', Int16),\n",
              "        ('day_of_week', Int8),\n",
              "        ('is_weekend', Boolean),\n",
              "        ('ts_day', Date),\n",
              "        ('is_dawn', Boolean),\n",
              "        ('timeofday_bucket', String),\n",
              "        ('log_amount_paid_usd', Float32),\n",
              "        ('log_amount_received_usd', Float32),\n",
              "        ('is_round_1000_paid', Boolean),\n",
              "        ('is_round_1000_received', Boolean),\n",
              "        ('is_round_10000_paid', Boolean),\n",
              "        ('is_ach', Boolean),\n",
              "        ('is_cheque', Boolean),\n",
              "        ('is_bitcoin_fmt', Boolean),\n",
              "        ('is_cash', Boolean),\n",
              "        ('is_credit_card', Boolean),\n",
              "        ('is_wire', Boolean),\n",
              "        ('is_reinvestment', Boolean),\n",
              "        ('is_crypto_transfer', Boolean),\n",
              "        ('is_high_value_ach', Boolean),\n",
              "        ('payment_method_risk', Float32),\n",
              "        ('risk_x_log_paid', Float32),\n",
              "        ('ach_x_log_paid', Float32),\n",
              "        ('btc_x_log_paid', Float32),\n",
              "        ('sender_entity_type_score', Float32),\n",
              "        ('receiver_entity_type_score', Float32),\n",
              "        ('high_risk_sender_bank_flag', Boolean),\n",
              "        ('high_risk_receiver_bank_flag', Boolean)])"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#“이 컬럼이 numeric / categorical인지” 빠르게 나누기\n",
        "schema = q_model.schema\n",
        "\n",
        "numeric_cols = [\n",
        "    c for c, d in schema.items()\n",
        "    if d in (\n",
        "        pl.Int8, pl.Int16, pl.Int32, pl.Int64,\n",
        "        pl.Float32, pl.Float64,\n",
        "        pl.Boolean,   # ✅ 추가\n",
        "    )\n",
        "]\n",
        "\n",
        "categorical_cols = [\n",
        "    c for c, d in schema.items()\n",
        "    if d in (pl.Utf8, pl.Categorical)\n",
        "]\n",
        "\n",
        "print(\"Numeric:\", numeric_cols)\n",
        "print(\"Categorical:\", categorical_cols)"
      ],
      "metadata": {
        "id": "Y5IkvC70NDPv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "60eddf46-4a15-487f-c61d-294bebe8523c"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Numeric: ['From Bank', 'To Bank', 'Is Laundering', 'Amount_Received_USD', 'Amount_Paid_USD', 'hour', 'day_of_week', 'is_weekend', 'is_dawn', 'log_amount_paid_usd', 'log_amount_received_usd', 'is_round_1000_paid', 'is_round_1000_received', 'is_round_10000_paid', 'is_ach', 'is_cheque', 'is_bitcoin_fmt', 'is_cash', 'is_credit_card', 'is_wire', 'is_reinvestment', 'is_crypto_transfer', 'is_high_value_ach', 'payment_method_risk', 'risk_x_log_paid', 'ach_x_log_paid', 'btc_x_log_paid', 'sender_entity_type_score', 'receiver_entity_type_score', 'high_risk_sender_bank_flag', 'high_risk_receiver_bank_flag']\n",
            "Categorical: ['From Account', 'To Account', 'Receiving Currency', 'Payment Currency', 'Payment Format', 'Sender_Entity', 'Sender_Bank_Name', 'Receiver_Entity', 'Receiver_Bank_Name', 'split', 'timeofday_bucket']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 10) 마지막에 pandas로 collect"
      ],
      "metadata": {
        "id": "iY8hlHNyp8u7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "split_counts = (\n",
        "    q_feat.group_by(\"split\")\n",
        "          .agg(pl.count().alias(\"rows\"))\n",
        "          .collect()\n",
        ")\n",
        "print(split_counts)"
      ],
      "metadata": {
        "id": "wJywMtUORLxg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3d533480-fb72-432e-c530-26fa51994bf5"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "shape: (3, 2)\n",
            "┌───────┬──────────┐\n",
            "│ split ┆ rows     │\n",
            "│ ---   ┆ ---      │\n",
            "│ str   ┆ u32      │\n",
            "╞═══════╪══════════╡\n",
            "│ test  ┆ 6378958  │\n",
            "│ train ┆ 19139731 │\n",
            "│ val   ┆ 6379980  │\n",
            "└───────┴──────────┘\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "label_dist = (\n",
        "    q_feat.group_by([\"split\", \"Is Laundering\"])\n",
        "          .agg(pl.count().alias(\"rows\"))\n",
        "          .sort([\"split\", \"Is Laundering\"])\n",
        "          .collect()\n",
        ")\n",
        "print(label_dist)"
      ],
      "metadata": {
        "id": "StUGfOWAROw_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "03554d2f-7777-4b51-b2ae-f25a74fcf339"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "shape: (6, 3)\n",
            "┌───────┬───────────────┬──────────┐\n",
            "│ split ┆ Is Laundering ┆ rows     │\n",
            "│ ---   ┆ ---           ┆ ---      │\n",
            "│ str   ┆ i64           ┆ u32      │\n",
            "╞═══════╪═══════════════╪══════════╡\n",
            "│ test  ┆ 0             ┆ 6368318  │\n",
            "│ test  ┆ 1             ┆ 10640    │\n",
            "│ train ┆ 0             ┆ 19124195 │\n",
            "│ train ┆ 1             ┆ 15536    │\n",
            "│ val   ┆ 0             ┆ 6370926  │\n",
            "│ val   ┆ 1             ┆ 9054     │\n",
            "└───────┴───────────────┴──────────┘\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================================================\n",
        "# sklearn로 넘기기 위한 \"컬럼만\" 선택 후 collect\n",
        "# =========================================================\n",
        "label_col = \"Is Laundering\"\n",
        "META_COLS = [\"ts_day\"]  # KPI용 메타\n",
        "\n",
        "feature_cols = [\n",
        "    c for c in q_model.columns\n",
        "    if c not in ([\"split\", label_col] + META_COLS)\n",
        "]\n",
        "\n",
        "q_train = (\n",
        "    q_model.filter(pl.col(\"split\") == \"train\")\n",
        "          .select(feature_cols + [label_col] + META_COLS)\n",
        ")\n",
        "train_df = q_train.collect().to_pandas()\n",
        "\n",
        "q_val = (\n",
        "    q_model.filter(pl.col(\"split\") == \"val\")\n",
        "          .select(feature_cols + [label_col] + META_COLS)\n",
        ")\n",
        "val_df   = q_val.collect().to_pandas()\n",
        "\n",
        "q_test = (\n",
        "    q_model.filter(pl.col(\"split\") == \"test\")\n",
        "          .select(feature_cols + [label_col] + META_COLS)\n",
        ")\n",
        "test_df  = q_test.collect().to_pandas()\n",
        "\n",
        "print(train_df.shape, val_df.shape, test_df.shape)"
      ],
      "metadata": {
        "id": "Dc3Xza9SSXop",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "793a0368-a4e6-4fc7-ca3b-2f8bde6d3929"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(19139731, 42) (6379980, 42) (6378958, 42)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 11) Top-k 로직(하루 기준/누적 기준)"
      ],
      "metadata": {
        "id": "1QKChchWckV9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Top-k 로직 교체용 함수:“k개 적발하려면 몇 건을 봐야 하는지”를 계산하는 함수\n",
        "def workload_to_find_k_positives(y_true, y_score, k_pos):\n",
        "    \"\"\"\n",
        "    목표: true positive를 k_pos개 '찾기' 위해\n",
        "         상위 점수부터 몇 건(N)을 조사해야 하는지 계산\n",
        "\n",
        "    Returns:\n",
        "      N_required: 필요한 조사 건수\n",
        "      precision:  k_found / N_required\n",
        "      recall:     k_found / total_pos\n",
        "      f1:         f1 (top-N을 양성으로 가정한 경우)\n",
        "      k_found:    실제로 찾은 TP 수 (total_pos < k_pos면 total_pos)\n",
        "    \"\"\"\n",
        "    y_true = np.asarray(y_true).astype(int)\n",
        "    y_score = np.asarray(y_score)\n",
        "\n",
        "    total_pos = y_true.sum()\n",
        "    if total_pos == 0:\n",
        "        return 0, 0.0, 0.0, 0.0, 0\n",
        "\n",
        "    # 점수 내림차순 정렬\n",
        "    order = np.argsort(-y_score)\n",
        "    y_sorted = y_true[order]\n",
        "\n",
        "    # 누적 TP\n",
        "    cum_tp = np.cumsum(y_sorted)\n",
        "\n",
        "    target = min(k_pos, int(total_pos))\n",
        "\n",
        "    # cum_tp >= target 되는 첫 index\n",
        "    idx = np.searchsorted(cum_tp, target, side=\"left\")\n",
        "    N_required = int(idx + 1)  # index -> count\n",
        "\n",
        "    k_found = int(cum_tp[idx])  # 보통 target과 같음(동점/중복 없으면)\n",
        "\n",
        "    precision = k_found / (N_required + 1e-12)\n",
        "    recall = k_found / (total_pos + 1e-12)\n",
        "\n",
        "    # top-N을 양성으로 보면: TP=k_found, FP=N-TP, FN=total_pos-TP\n",
        "    fp = N_required - k_found\n",
        "    fn = total_pos - k_found\n",
        "    f1 = (2 * k_found) / (2 * k_found + fp + fn + 1e-12)\n",
        "\n",
        "    return N_required, precision, recall, f1, k_found"
      ],
      "metadata": {
        "id": "oDztbg2uc2ak"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def per_day_workload_summary(df, day_col, label_col, score_col, k_pos_list=(30,50,100,200)):\n",
        "    \"\"\"\n",
        "    df: pandas DataFrame with [day_col, label_col, score_col]\n",
        "    day별로 'k_pos개 적발하기 위해 필요한 조사량 N' 계산 후\n",
        "    k_pos마다 daily 분포 + mean/median/p90 요약을 반환\n",
        "    \"\"\"\n",
        "    out_rows = []\n",
        "    for day, g in df.groupby(day_col):\n",
        "        y = g[label_col].astype(int).values\n",
        "        s = g[score_col].values\n",
        "        total_pos = int(y.sum())\n",
        "        n = len(g)\n",
        "\n",
        "        for k_pos in k_pos_list:\n",
        "            N_req, p, r, f1, found = workload_to_find_k_positives(y, s, k_pos)\n",
        "            out_rows.append({\n",
        "                \"day\": day,\n",
        "                \"n_rows\": n,\n",
        "                \"pos\": total_pos,\n",
        "                \"k_pos\": k_pos,\n",
        "                \"N_required\": N_req,\n",
        "                \"precision_at_Nk\": p,\n",
        "                \"recall_at_Nk\": r,\n",
        "                \"f1_at_Nk\": f1,\n",
        "                \"found_tp\": found,\n",
        "                \"target_k\": min(k_pos, total_pos),\n",
        "                \"hit_target\": (found >= min(k_pos, total_pos)) and (total_pos > 0)\n",
        "            })\n",
        "\n",
        "    daily = pd.DataFrame(out_rows)\n",
        "\n",
        "    # day에 pos=0이면 N_required=0이 되고 의미가 약하니,\n",
        "    # 운영 KPI로는 \"pos>0인 day\"만 요약하는게 보통 더 깔끔함\n",
        "    daily_pos = daily[daily[\"pos\"] > 0].copy()\n",
        "\n",
        "    def summarize(sub):\n",
        "        # N_required는 \"작을수록 좋음\"\n",
        "        return pd.Series({\n",
        "            \"days\": sub[\"day\"].nunique(),\n",
        "            \"mean_N_required\": sub[\"N_required\"].mean(),\n",
        "            \"median_N_required\": sub[\"N_required\"].median(),\n",
        "            \"p90_N_required\": sub[\"N_required\"].quantile(0.90),\n",
        "            \"mean_precision\": sub[\"precision_at_Nk\"].mean(),\n",
        "            \"median_precision\": sub[\"precision_at_Nk\"].median(),\n",
        "            \"p90_precision\": sub[\"precision_at_Nk\"].quantile(0.90),\n",
        "        })\n",
        "\n",
        "    summary = (\n",
        "        daily_pos\n",
        "        .groupby(\"k_pos\", as_index=False)\n",
        "        .apply(summarize)\n",
        "        .reset_index(drop=True)\n",
        "    )\n",
        "\n",
        "    return daily, summary"
      ],
      "metadata": {
        "id": "ZHdtd3nRdzSU"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def log_per_day_kpi_to_wandb(split_name, df_raw_with_day, y_true, y_score, k_list=(30,50,100,200)):\n",
        "    \"\"\"\n",
        "    split_name: \"val\" or \"test\"\n",
        "    df_raw_with_day: pandas DF that includes column \"ts_day\" aligned with y_true/y_score index\n",
        "    y_true/y_score: numpy-like aligned arrays\n",
        "    \"\"\"\n",
        "    tmp = pd.DataFrame({\n",
        "        \"ts_day\": df_raw_with_day[\"ts_day\"].values,\n",
        "        \"label\": np.asarray(y_true).astype(int),\n",
        "        \"score\": np.asarray(y_score),\n",
        "    })\n",
        "\n",
        "    daily, summary = per_day_workload_summary(\n",
        "        tmp,\n",
        "        day_col=\"ts_day\",\n",
        "        label_col=\"label\",\n",
        "        score_col=\"score\",\n",
        "        k_pos_list=k_list\n",
        "    )\n",
        "\n",
        "    # (A) 요약 로그: k별 mean/median/p90\n",
        "    for _, row in summary.iterrows():\n",
        "        k = int(row[\"k_pos\"])\n",
        "        wandb.log({\n",
        "            f\"{split_name}_perday_find_{k}_mean_N\": float(row[\"mean_N_required\"]),\n",
        "            f\"{split_name}_perday_find_{k}_median_N\": float(row[\"median_N_required\"]),\n",
        "            f\"{split_name}_perday_find_{k}_p90_N\": float(row[\"p90_N_required\"]),\n",
        "            f\"{split_name}_perday_find_{k}_mean_precision\": float(row[\"mean_precision\"]),\n",
        "            f\"{split_name}_perday_find_{k}_median_precision\": float(row[\"median_precision\"]),\n",
        "            f\"{split_name}_perday_find_{k}_p90_precision\": float(row[\"p90_precision\"]),\n",
        "            f\"{split_name}_perday_days_with_pos_{k}\": int(row[\"days\"]),\n",
        "        })\n",
        "\n",
        "    # (B) 분포 확인용 테이블(너무 크면 상위 일부만)\n",
        "    # day*k 만큼 행이 생김 -> 기간 짧으면 OK, 길면 샘플링/요약만 남기기\n",
        "    table = wandb.Table(dataframe=daily.head(5000))\n",
        "    wandb.log({f\"{split_name}_perday_workload_table\": table})"
      ],
      "metadata": {
        "id": "6JaOcz2-fTHd"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def score_bin_distribution(y_true, y_score, n_bins=10, score_scale=1000):\n",
        "    \"\"\"\n",
        "    score를 0~score_scale로 스케일링한 뒤,\n",
        "    bin별 label(0/1) 건수 집계.\n",
        "    항상 normal_cnt / laundering_cnt 컬럼이 존재하도록 보정.\n",
        "    \"\"\"\n",
        "    y = np.asarray(y_true).astype(int)\n",
        "    s = np.asarray(y_score)\n",
        "\n",
        "    s_scaled = np.clip(s * score_scale, 0, score_scale)\n",
        "    bins = np.linspace(0, score_scale, n_bins + 1)\n",
        "\n",
        "    # 0..n_bins-1\n",
        "    bin_idx = np.digitize(s_scaled, bins, right=False) - 1\n",
        "    bin_idx = np.clip(bin_idx, 0, n_bins - 1)\n",
        "\n",
        "    df = pd.DataFrame({\"bin\": bin_idx, \"label\": y})\n",
        "\n",
        "    # label별 count (항상 0/1 둘 다 컬럼을 만들도록 reindex)\n",
        "    cnt = (\n",
        "        df.groupby([\"bin\", \"label\"])\n",
        "          .size()\n",
        "          .unstack(fill_value=0)\n",
        "          .reindex(columns=[0, 1], fill_value=0)   # ✅ 핵심\n",
        "          .rename(columns={0: \"normal_cnt\", 1: \"laundering_cnt\"})\n",
        "          .reset_index()\n",
        "    )\n",
        "\n",
        "    # bin_range 붙이기\n",
        "    cnt[\"bin_range\"] = cnt[\"bin\"].apply(lambda i: f\"{int(bins[i])}-{int(bins[i+1])}\")\n",
        "\n",
        "    # 보기 좋게 정렬\n",
        "    cnt = cnt[[\"bin\", \"bin_range\", \"normal_cnt\", \"laundering_cnt\"]]\n",
        "    return cnt"
      ],
      "metadata": {
        "id": "pKLiVoBXVc5M"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 12-1) W&B Sweeps용 train/eval 함수 정의(xgboost)"
      ],
      "metadata": {
        "id": "AIEyQ8_oqMK6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_eval_sweep():\n",
        "    \"\"\"\n",
        "    W&B agent가 호출하는 sweep train function.\n",
        "    - run 안에서 transformer fit은 train만\n",
        "    - val/test는 transform만 (누수 방지)\n",
        "    - scale_pos_weight sweep\n",
        "    - val 기준으로 sweep 최적화 metric 로깅\n",
        "    - PR curve / CM / Top-K는 val/test 각각 로깅\n",
        "    - XGB feature importance(gain) 로깅 (변환 후 feature name)\n",
        "    \"\"\"\n",
        "    run = wandb.init()\n",
        "    config = wandb.config\n",
        "\n",
        "    # =========================\n",
        "    # (0) RAW -> X/y 분리\n",
        "    # =========================\n",
        "    LABEL_COL = \"Is Laundering\"\n",
        "\n",
        "    # train/val/test는 \"이미 time split 완료된 pandas df\"라고 가정\n",
        "    # (run 밖에서 만들어둔 걸 그대로 씀)\n",
        "    X_train_raw = train_df.drop(columns=[LABEL_COL, \"ts_day\"])\n",
        "    y_train     = train_df[LABEL_COL].astype(int)\n",
        "\n",
        "    X_val_raw   = val_df.drop(columns=[LABEL_COL, \"ts_day\"])\n",
        "    y_val       = val_df[LABEL_COL].astype(int)\n",
        "\n",
        "    X_test_raw  = test_df.drop(columns=[LABEL_COL, \"ts_day\"])\n",
        "    y_test      = test_df[LABEL_COL].astype(int)\n",
        "\n",
        "    # =========================\n",
        "    # (1) 컬럼 타입 분리 (run마다 동일하지만 안전하게 여기서)\n",
        "    # =========================\n",
        "    categorical_features = X_train_raw.select_dtypes(include=[\"object\", \"category\", \"string\"]).columns.tolist()\n",
        "    numerical_features   = [c for c in X_train_raw.columns if c not in categorical_features]\n",
        "\n",
        "    # =========================\n",
        "    # (2) Transformer 정의 & fit/transform (누수 방지 핵심)\n",
        "    # =========================\n",
        "    num_pipe = Pipeline(steps=[\n",
        "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
        "        # XGBoost면 보통 스케일링 생략 가능 (원하면 config로 켜도 됨)\n",
        "    ])\n",
        "\n",
        "    cat_pipe = Pipeline(steps=[\n",
        "        (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
        "        (\"enc\", OrdinalEncoder(handle_unknown=\"use_encoded_value\", unknown_value=-1)),\n",
        "    ])\n",
        "\n",
        "    transformer = ColumnTransformer(\n",
        "        transformers=[\n",
        "            (\"num\", num_pipe, numerical_features),\n",
        "            (\"cat\", cat_pipe, categorical_features),\n",
        "        ],\n",
        "        remainder=\"drop\",\n",
        "        verbose_feature_names_out=False,  # get_feature_names_out 깔끔하게\n",
        "    )\n",
        "\n",
        "    # ✅ fit은 train만\n",
        "    X_train = transformer.fit_transform(X_train_raw)\n",
        "    # ✅ val/test는 transform만\n",
        "    X_val   = transformer.transform(X_val_raw)\n",
        "    X_test  = transformer.transform(X_test_raw)\n",
        "\n",
        "    # 변환 후 feature name 확보 (importance 로깅용)\n",
        "    try:\n",
        "        feature_names = transformer.get_feature_names_out()\n",
        "        feature_names = [str(x) for x in feature_names]\n",
        "    except Exception:\n",
        "        feature_names = [f\"f{i}\" for i in range(X_train.shape[1])]\n",
        "\n",
        "    # =========================\n",
        "    # (A) 모델 생성 (sweep 파라미터)\n",
        "    # =========================\n",
        "    xgb_model = XGBClassifier(\n",
        "        n_estimators=config.n_estimators,\n",
        "        max_depth=config.max_depth,\n",
        "        learning_rate=config.learning_rate,\n",
        "        subsample=config.subsample,\n",
        "        colsample_bytree=config.colsample_bytree,\n",
        "        reg_lambda=config.reg_lambda,\n",
        "        reg_alpha=config.reg_alpha,\n",
        "        min_child_weight=config.min_child_weight,\n",
        "        gamma=config.gamma,\n",
        "        scale_pos_weight=config.scale_pos_weight,   # ✅ sweep\n",
        "        eval_metric=\"logloss\",\n",
        "        random_state=42,\n",
        "        n_jobs=-1\n",
        "    )\n",
        "\n",
        "    # =========================\n",
        "    # (B) 학습\n",
        "    # =========================\n",
        "    xgb_model.fit(X_train, y_train)\n",
        "\n",
        "    # =========================\n",
        "    # (C) 평가 (val/test 둘 다)\n",
        "    # =========================\n",
        "    def safe_auc_metrics(y_true, y_score):\n",
        "        if len(np.unique(y_true)) <= 1:\n",
        "            return np.nan, np.nan\n",
        "        return roc_auc_score(y_true, y_score), average_precision_score(y_true, y_score)\n",
        "\n",
        "    def topk_metrics(y_true, y_score, k):\n",
        "        k = min(k, len(y_true))\n",
        "        idx = np.argsort(-y_score)[:k]\n",
        "        y_pred = np.zeros_like(y_true)\n",
        "        y_pred[idx] = 1\n",
        "        p = precision_score(y_true, y_pred, zero_division=0)\n",
        "        r = recall_score(y_true, y_pred, zero_division=0)\n",
        "        f = f1_score(y_true, y_pred, zero_division=0)\n",
        "        return p, r, f\n",
        "\n",
        "    def threshold_at_recall(y_true, y_score, desired_recall=0.90):\n",
        "        prec, rec, thr = precision_recall_curve(y_true, y_score)\n",
        "        if len(thr) == 0:\n",
        "            return 0.5, prec, rec, thr\n",
        "        closest_i = np.argmin(np.abs(rec[1:] - desired_recall))\n",
        "        return float(thr[closest_i]), prec, rec, thr\n",
        "\n",
        "    # -------------------------\n",
        "    # (C-1) val / test 확률 예측\n",
        "    # -------------------------\n",
        "    prob_val  = xgb_model.predict_proba(X_val)[:, 1]\n",
        "    prob_test = xgb_model.predict_proba(X_test)[:, 1]\n",
        "\n",
        "    val_roc_auc,  val_auprc  = safe_auc_metrics(y_val, prob_val)\n",
        "    test_roc_auc, test_auprc = safe_auc_metrics(y_test, prob_test)\n",
        "\n",
        "    # ✅ sweep 최적화 metric은 val 기준으로 통일\n",
        "    wandb.log({\n",
        "        \"val_roc_auc\":  val_roc_auc,\n",
        "        \"val_auprc\":    val_auprc,\n",
        "        \"test_roc_auc\": test_roc_auc,\n",
        "        \"test_auprc\":   test_auprc,\n",
        "        \"n_train\": len(y_train),\n",
        "        \"pos_train\": int(np.sum(y_train)),\n",
        "        \"pos_val\": int(np.sum(y_val)),\n",
        "        \"pos_test\": int(np.sum(y_test)),\n",
        "    })\n",
        "\n",
        "    # -------------------------\n",
        "    # (C-2) PR Curve 로깅 (val/test 각각)\n",
        "    # -------------------------\n",
        "    # PR curve 로깅 (val/test)\n",
        "    prec_v, rec_v, _ = precision_recall_curve(y_val, prob_val)\n",
        "    fig_pr_v = plt.figure()\n",
        "    plt.plot(rec_v, prec_v)\n",
        "    plt.xlabel(\"Recall\"); plt.ylabel(\"Precision\")\n",
        "    plt.title(f\"VAL PR Curve (AUPRC={val_auprc:.4f})\")\n",
        "    wandb.log({\"val_pr_curve\": wandb.Image(fig_pr_v)})\n",
        "    plt.close(fig_pr_v)\n",
        "\n",
        "    prec_t, rec_t, _ = precision_recall_curve(y_test, prob_test)\n",
        "    fig_pr_t = plt.figure()\n",
        "    plt.plot(rec_t, prec_t)\n",
        "    plt.xlabel(\"Recall\"); plt.ylabel(\"Precision\")\n",
        "    plt.title(f\"TEST PR Curve (AUPRC={test_auprc:.4f})\")\n",
        "    wandb.log({\"test_pr_curve\": wandb.Image(fig_pr_t)})\n",
        "    plt.close(fig_pr_t)\n",
        "\n",
        "    # -------------------------\n",
        "    # (C-3) Top-k\n",
        "    # -------------------------\n",
        "    # \"K TP 찾기 위한 조사량\" 로깅 (val/test 각각)\n",
        "    for k_pos in [450, 750, 1500, 3000]:\n",
        "        N_v, p_v, r_v, f_v, found_v = workload_to_find_k_positives(y_val.values, prob_val, k_pos)\n",
        "        N_t, p_t, r_t, f_t, found_t = workload_to_find_k_positives(y_test.values, prob_test, k_pos)\n",
        "\n",
        "        wandb.log({\n",
        "            # VAL\n",
        "            f\"val_find_{k_pos}_N_required\": N_v,\n",
        "            f\"val_find_{k_pos}_precision\": p_v,\n",
        "            f\"val_find_{k_pos}_recall\":    r_v,\n",
        "            f\"val_find_{k_pos}_f1\":        f_v,\n",
        "            f\"val_find_{k_pos}_found_tp\":  found_v,\n",
        "\n",
        "            # TEST\n",
        "            f\"test_find_{k_pos}_N_required\": N_t,\n",
        "            f\"test_find_{k_pos}_precision\": p_t,\n",
        "            f\"test_find_{k_pos}_recall\":    r_t,\n",
        "            f\"test_find_{k_pos}_f1\":        f_t,\n",
        "            f\"test_find_{k_pos}_found_tp\":  found_t,\n",
        "        })\n",
        "\n",
        "    # per-day KPI 로깅 (VAL/TEST 각각)\n",
        "    # 전제: val_df/test_df에 ts_day 컬럼 존재\n",
        "    log_per_day_kpi_to_wandb(\"val\",  val_df,  y_val.values,  prob_val,  k_list=(30,50,100,200))\n",
        "    log_per_day_kpi_to_wandb(\"test\", test_df, y_test.values, prob_test, k_list=(30,50,100,200))\n",
        "\n",
        "    dist_val  = score_bin_distribution(y_val.values,  prob_val,  n_bins=10, score_scale=1000)\n",
        "    dist_test = score_bin_distribution(y_test.values, prob_test, n_bins=10, score_scale=1000)\n",
        "    wandb.log({\n",
        "        \"val_score_bin_table\":  wandb.Table(dataframe=dist_val),\n",
        "        \"test_score_bin_table\": wandb.Table(dataframe=dist_test),\n",
        "    })\n",
        "\n",
        "    # -------------------------\n",
        "    # (C-4) threshold@recall (val에서 threshold 선택 → test에 적용)\n",
        "    # -------------------------\n",
        "    desired_recall = 0.90\n",
        "    chosen_thr, _, _, _ = threshold_at_recall(y_val, prob_val, desired_recall)\n",
        "\n",
        "    # ✅ thr 기반 예측(한 번만)\n",
        "    y_val_pred  = (prob_val  >= chosen_thr).astype(int)\n",
        "    y_test_pred = (prob_test >= chosen_thr).astype(int)\n",
        "\n",
        "    # ✅ CM (thr 기반)\n",
        "    cm_val  = confusion_matrix(y_val,  y_val_pred)\n",
        "    cm_test = confusion_matrix(y_test, y_test_pred)\n",
        "\n",
        "    fig_cm_v = plt.figure(figsize=(6,4))\n",
        "    sns.heatmap(cm_val, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
        "    plt.xlabel(\"Predicted\"); plt.ylabel(\"True\")\n",
        "    plt.title(f\"VAL CM @thr={chosen_thr:.4f}\")\n",
        "    wandb.log({\"val_confusion_matrix\": wandb.Image(fig_cm_v)})\n",
        "    plt.close(fig_cm_v)\n",
        "\n",
        "    fig_cm_t = plt.figure(figsize=(6,4))\n",
        "    sns.heatmap(cm_test, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
        "    plt.xlabel(\"Predicted\"); plt.ylabel(\"True\")\n",
        "    plt.title(f\"TEST CM @thr={chosen_thr:.4f}\")\n",
        "    wandb.log({\"test_confusion_matrix\": wandb.Image(fig_cm_t)})\n",
        "    plt.close(fig_cm_t)\n",
        "\n",
        "    # =========================\n",
        "    # (C-4-2) Precision / Recall / F1\n",
        "    # =========================\n",
        "\n",
        "    # (A) chosen_thr 기준 (운영)\n",
        "    val_precision_thr  = precision_score(y_val,  y_val_pred,  zero_division=0)\n",
        "    val_recall_thr     = recall_score(y_val,     y_val_pred,  zero_division=0)\n",
        "    val_f1_thr         = f1_score(y_val,         y_val_pred,  zero_division=0)\n",
        "\n",
        "    test_precision_thr = precision_score(y_test, y_test_pred, zero_division=0)\n",
        "    test_recall_thr    = recall_score(y_test,    y_test_pred, zero_division=0)\n",
        "    test_f1_thr        = f1_score(y_test,        y_test_pred, zero_division=0)\n",
        "\n",
        "    # (B) 0.5 기준 (참고)\n",
        "    thr_05 = 0.5\n",
        "    y_val_pred_05  = (prob_val  >= thr_05).astype(int)\n",
        "    y_test_pred_05 = (prob_test >= thr_05).astype(int)\n",
        "\n",
        "    val_precision_05  = precision_score(y_val,  y_val_pred_05,  zero_division=0)\n",
        "    val_recall_05     = recall_score(y_val,     y_val_pred_05,  zero_division=0)\n",
        "    val_f1_05         = f1_score(y_val,         y_val_pred_05,  zero_division=0)\n",
        "\n",
        "    test_precision_05 = precision_score(y_test, y_test_pred_05, zero_division=0)\n",
        "    test_recall_05    = recall_score(y_test,    y_test_pred_05, zero_division=0)\n",
        "    test_f1_05        = f1_score(y_test,        y_test_pred_05, zero_division=0)\n",
        "\n",
        "    # ✅ 로그(한 번에)\n",
        "    wandb.log({\n",
        "        \"desired_recall_for_thr\": float(desired_recall),\n",
        "        \"chosen_threshold\": float(chosen_thr),\n",
        "\n",
        "        \"val_precision_thr\":  float(val_precision_thr),\n",
        "        \"val_recall_thr\":     float(val_recall_thr),\n",
        "        \"val_f1_thr\":         float(val_f1_thr),\n",
        "        \"test_precision_thr\": float(test_precision_thr),\n",
        "        \"test_recall_thr\":    float(test_recall_thr),\n",
        "        \"test_f1_thr\":        float(test_f1_thr),\n",
        "\n",
        "        \"val_precision_thr_0.5\":  float(val_precision_05),\n",
        "        \"val_recall_thr_0.5\":     float(val_recall_05),\n",
        "        \"val_f1_thr_0.5\":         float(val_f1_05),\n",
        "        \"test_precision_thr_0.5\": float(test_precision_05),\n",
        "        \"test_recall_thr_0.5\":    float(test_recall_05),\n",
        "        \"test_f1_thr_0.5\":        float(test_f1_05),\n",
        "    })\n",
        "\n",
        "    # =========================\n",
        "    # (C-5) Feature Importance (gain)\n",
        "    # =========================\n",
        "    booster = xgb_model.get_booster()\n",
        "    gain_dict = booster.get_score(importance_type=\"gain\")\n",
        "\n",
        "    if len(gain_dict) > 0:\n",
        "        imp_rows = []\n",
        "        for k, v in gain_dict.items():\n",
        "            try:\n",
        "                idx = int(k[1:])\n",
        "            except Exception:\n",
        "                continue\n",
        "            name = feature_names[idx] if idx < len(feature_names) else k\n",
        "            imp_rows.append((name, float(v)))\n",
        "\n",
        "        imp_rows.sort(key=lambda x: x[1], reverse=True)\n",
        "\n",
        "        # (1) ✅ 전체 table 로깅\n",
        "        table_all = wandb.Table(columns=[\"feature\", \"gain\"])\n",
        "        for name, gain in imp_rows:\n",
        "            table_all.add_data(name, gain)\n",
        "        wandb.log({\"feature_importance_gain_table_all\": table_all})\n",
        "\n",
        "        # (2) bar는 top만\n",
        "        topN_bar = int(getattr(config, \"topn_importance\", 50)) if hasattr(config, \"topn_importance\") else 50\n",
        "        imp_top = imp_rows[:topN_bar]\n",
        "\n",
        "        fig_imp = plt.figure(figsize=(8, 10))\n",
        "        names = [x[0] for x in imp_top][::-1]\n",
        "        vals  = [x[1] for x in imp_top][::-1]\n",
        "        plt.barh(names, vals)\n",
        "        plt.xlabel(\"Gain\")\n",
        "        plt.title(f\"Top-{len(imp_top)} Feature Importance (Gain)\")\n",
        "        wandb.log({\"feature_importance_gain_bar_top\": wandb.Image(fig_imp)})\n",
        "        plt.close(fig_imp)\n",
        "\n",
        "    # =========================\n",
        "    # (D) 콘솔 리포트 (test)\n",
        "    # =========================\n",
        "    print(\"=== Sweep Report ===\")\n",
        "    print(\"VAL  ROC-AUC:\", val_roc_auc,  \"VAL  AUPRC:\", val_auprc)\n",
        "    print(\"TEST ROC-AUC:\", test_roc_auc, \"TEST AUPRC:\", test_auprc)\n",
        "    print(\"Chosen thr(from VAL):\", chosen_thr)\n",
        "    print(classification_report(y_test, y_test_pred, zero_division=0))\n",
        "\n",
        "    # =========================\n",
        "    # (E) Artifacts 저장/업로드\n",
        "    # =========================\n",
        "    os.makedirs(\"artifacts_out\", exist_ok=True)\n",
        "\n",
        "    preproc_path = \"artifacts_out/transformer.joblib\"\n",
        "    joblib.dump(transformer, preproc_path)\n",
        "\n",
        "    model_joblib_path = \"artifacts_out/aml_model.joblib\"\n",
        "    joblib.dump(xgb_model, model_joblib_path)\n",
        "\n",
        "    model_pkl_path = \"artifacts_out/aml_model.pkl\"\n",
        "    with open(model_pkl_path, \"wb\") as f:\n",
        "        pickle.dump(xgb_model, f)\n",
        "\n",
        "    # (선택) 데이터 샘플 저장\n",
        "    data_sample_path = \"artifacts_out/train_sample.csv\"\n",
        "    try:\n",
        "        sample_n = 2000\n",
        "        X_train_raw_sample = X_train_raw.head(sample_n).copy()\n",
        "        y_train_sample = y_train.loc[X_train_raw_sample.index].copy()\n",
        "        X_train_raw_sample[LABEL_COL] = y_train_sample\n",
        "        X_train_raw_sample.to_csv(data_sample_path, index=False)\n",
        "        include_sample = True\n",
        "    except Exception:\n",
        "        include_sample = False\n",
        "\n",
        "    art = wandb.Artifact(\n",
        "        name=\"aml_bundle\",\n",
        "        type=\"model\",\n",
        "        description=\"Transformer(train-only fit) + XGB(scale_pos_weight sweep) + optional data sample\"\n",
        "    )\n",
        "    art.add_file(preproc_path)\n",
        "    art.add_file(model_joblib_path)\n",
        "    art.add_file(model_pkl_path)\n",
        "    if include_sample:\n",
        "        art.add_file(data_sample_path)\n",
        "\n",
        "    wandb.log_artifact(art)\n",
        "\n",
        "    run.finish()"
      ],
      "metadata": {
        "id": "tZ9YULH7d1RJ"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 12-2) Sweep Config 정의 + 실행"
      ],
      "metadata": {
        "id": "2aEJaEYnqPtB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sweep_config = {\n",
        "    \"method\": \"bayes\",\n",
        "    \"metric\": {\"name\": \"val_auprc\", \"goal\": \"maximize\"},  # ★ 수정\n",
        "    \"parameters\": {\n",
        "        \"n_estimators\": {\"values\": [600]},\n",
        "        \"max_depth\": {\"values\": [8]},\n",
        "        \"learning_rate\": {\"values\": [0.1]},\n",
        "        \"subsample\": {\"values\": [0.7]},\n",
        "        \"colsample_bytree\": {\"values\": [1.0]},\n",
        "        \"reg_lambda\": {\"values\": [5.0]},\n",
        "        \"reg_alpha\": {\"values\": [0.5]},\n",
        "        \"min_child_weight\": {\"values\": [10]},\n",
        "        \"gamma\": {\"values\": [0.5]},\n",
        "        \"scale_pos_weight\": {\"values\": [1.0]},  # ★ 추가\n",
        "    }\n",
        "}\n",
        "\n",
        "# (프로젝트/엔티티 이름은 팀 기준으로 정해줘)\n",
        "sweep_id = wandb.sweep(sweep_config, project=\"eungyulwon\")\n",
        "\n",
        "# count: 몇 번의 실험(run)을 돌릴지\n",
        "wandb.agent(sweep_id, function=train_eval_sweep, count=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "KWg0GPHaVbqf",
        "outputId": "fa92d91d-80de-4162-9c84-cb1a1cab0edc"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Create sweep with ID: svpv850k\n",
            "Sweep URL: https://wandb.ai/0326byeol-korea-ac-kr/eungyulwon/sweeps/svpv850k\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: owq43yud with config:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tcolsample_bytree: 1\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tgamma: 0.5\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.1\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tmax_depth: 8\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tmin_child_weight: 10\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_estimators: 600\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \treg_alpha: 0.5\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \treg_lambda: 5\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tscale_pos_weight: 1\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tsubsample: 0.7\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: [wandb.login()] Loaded credentials for https://api.wandb.ai from /root/.netrc.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.24.1"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20260210_030453-owq43yud</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/0326byeol-korea-ac-kr/eungyulwon/runs/owq43yud' target=\"_blank\">silvery-sweep-1</a></strong> to <a href='https://wandb.ai/0326byeol-korea-ac-kr/eungyulwon' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/0326byeol-korea-ac-kr/eungyulwon/sweeps/svpv850k' target=\"_blank\">https://wandb.ai/0326byeol-korea-ac-kr/eungyulwon/sweeps/svpv850k</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/0326byeol-korea-ac-kr/eungyulwon' target=\"_blank\">https://wandb.ai/0326byeol-korea-ac-kr/eungyulwon</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View sweep at <a href='https://wandb.ai/0326byeol-korea-ac-kr/eungyulwon/sweeps/svpv850k' target=\"_blank\">https://wandb.ai/0326byeol-korea-ac-kr/eungyulwon/sweeps/svpv850k</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/0326byeol-korea-ac-kr/eungyulwon/runs/owq43yud' target=\"_blank\">https://wandb.ai/0326byeol-korea-ac-kr/eungyulwon/runs/owq43yud</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== Sweep Report ===\n",
            "VAL  ROC-AUC: 0.9799227482784912 VAL  AUPRC: 0.31476612142923177\n",
            "TEST ROC-AUC: 0.984481708271893 TEST AUPRC: 0.44811858920485814\n",
            "Chosen thr(from VAL): 0.001552874338813126\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.93      0.97   6368318\n",
            "           1       0.02      0.91      0.04     10640\n",
            "\n",
            "    accuracy                           0.93   6378958\n",
            "   macro avg       0.51      0.92      0.50   6378958\n",
            "weighted avg       1.00      0.93      0.96   6378958\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>chosen_threshold</td><td>▁</td></tr><tr><td>desired_recall_for_thr</td><td>▁</td></tr><tr><td>n_train</td><td>▁</td></tr><tr><td>pos_test</td><td>▁</td></tr><tr><td>pos_train</td><td>▁</td></tr><tr><td>pos_val</td><td>▁</td></tr><tr><td>test_auprc</td><td>▁</td></tr><tr><td>test_f1_thr</td><td>▁</td></tr><tr><td>test_f1_thr_0.5</td><td>▁</td></tr><tr><td>test_find_1500_N_required</td><td>▁</td></tr><tr><td>+108</td><td>...</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>chosen_threshold</td><td>0.00155</td></tr><tr><td>desired_recall_for_thr</td><td>0.9</td></tr><tr><td>n_train</td><td>19139731</td></tr><tr><td>pos_test</td><td>10640</td></tr><tr><td>pos_train</td><td>15536</td></tr><tr><td>pos_val</td><td>9054</td></tr><tr><td>test_auprc</td><td>0.44812</td></tr><tr><td>test_f1_thr</td><td>0.04324</td></tr><tr><td>test_f1_thr_0.5</td><td>0.44919</td></tr><tr><td>test_find_1500_N_required</td><td>1972</td></tr><tr><td>+108</td><td>...</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">silvery-sweep-1</strong> at: <a href='https://wandb.ai/0326byeol-korea-ac-kr/eungyulwon/runs/owq43yud' target=\"_blank\">https://wandb.ai/0326byeol-korea-ac-kr/eungyulwon/runs/owq43yud</a><br> View project at: <a href='https://wandb.ai/0326byeol-korea-ac-kr/eungyulwon' target=\"_blank\">https://wandb.ai/0326byeol-korea-ac-kr/eungyulwon</a><br>Synced 5 W&B file(s), 10 media file(s), 15 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20260210_030453-owq43yud/logs</code>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# # v1 best run hyperparameters 주입, count = 1\n",
        "# sweep_config = {\n",
        "#     \"method\": \"bayes\",\n",
        "#     \"metric\": {\"name\": \"val_auprc\", \"goal\": \"maximize\"},  # ★ 수정\n",
        "#     \"parameters\": {\n",
        "#         \"n_estimators\": {\"values\": [600]},\n",
        "#         \"max_depth\": {\"values\": [8]},\n",
        "#         \"learning_rate\": {\"values\": [0.03]},\n",
        "#         \"subsample\": {\"values\": [0.9]},\n",
        "#         \"colsample_bytree\": {\"values\": [1.0]},\n",
        "#         \"reg_lambda\": {\"values\": [1.0]},\n",
        "#         \"reg_alpha\": {\"values\": [0.1]},\n",
        "#         \"min_child_weight\": {\"values\": [5]},\n",
        "#         \"gamma\": {\"values\": [0.5]},\n",
        "#         \"scale_pos_weight\": {\"values\": [1]},  # ★ 추가\n",
        "#     }\n",
        "# }\n",
        "\n",
        "# # (프로젝트/엔티티 이름은 팀 기준으로 정해줘)\n",
        "# sweep_id = wandb.sweep(sweep_config, project=\"eungyulwon\")\n",
        "\n",
        "# # count: 몇 번의 실험(run)을 돌릴지\n",
        "# wandb.agent(sweep_id, function=train_eval_sweep, count=1)"
      ],
      "metadata": {
        "id": "_mh6CQ7rhn1S"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # v2 best run hyperparameters 주입, count = 1\n",
        "# sweep_config = {\n",
        "#     \"method\": \"bayes\",\n",
        "#     \"metric\": {\"name\": \"val_auprc\", \"goal\": \"maximize\"},  # ★ 수정\n",
        "#     \"parameters\": {\n",
        "#         \"n_estimators\": {\"values\": [600]},\n",
        "#         \"max_depth\": {\"values\": [8]},\n",
        "#         \"learning_rate\": {\"values\": [0.1]},\n",
        "#         \"subsample\": {\"values\": [0.7]},\n",
        "#         \"colsample_bytree\": {\"values\": [1.0]},\n",
        "#         \"reg_lambda\": {\"values\": [5.0]},\n",
        "#         \"reg_alpha\": {\"values\": [0.5]},\n",
        "#         \"min_child_weight\": {\"values\": [10]},\n",
        "#         \"gamma\": {\"values\": [0.5]},\n",
        "#         \"scale_pos_weight\": {\"values\": [1]},  # ★ 추가\n",
        "#     }\n",
        "# }\n",
        "\n",
        "# # (프로젝트/엔티티 이름은 팀 기준으로 정해줘)\n",
        "# sweep_id = wandb.sweep(sweep_config, project=\"eungyulwon\")\n",
        "\n",
        "# # count: 몇 번의 실험(run)을 돌릴지\n",
        "# wandb.agent(sweep_id, function=train_eval_sweep, count=1)"
      ],
      "metadata": {
        "id": "kA2bVVoOwNYb"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 15) (선택) Artifacts \"불러오기\" 예시 (필요할 때만 실행)\n",
        "#     - W&B에서 best 모델 버전 지정해서 다시 로컬로 가져올 수 있음"
      ],
      "metadata": {
        "id": "6rzYPg0AwOIA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# run = wandb.init(project=\"aml-team-experiments\", job_type=\"inference\")\n",
        "# artifact = run.use_artifact(\"YOUR_ENTITY/aml-team-experiments/aml_xgb_bundle:latest\", type=\"model\")\n",
        "# artifact_dir = artifact.download()\n",
        "# loaded_transformer = joblib.load(os.path.join(artifact_dir, \"transformer.joblib\"))\n",
        "# loaded_model = joblib.load(os.path.join(artifact_dir, \"aml_model.joblib\"))\n",
        "# run.finish()\n",
        "\n",
        "# 이제 loaded_transformer/loaded_model로 동일 파이프라인 재현 가능"
      ],
      "metadata": {
        "id": "f8NwrVzHwV_b"
      },
      "execution_count": 42,
      "outputs": []
    }
  ]
}